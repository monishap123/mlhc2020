{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"MLHC_Project_3.ipynb","provenance":[],"private_outputs":true,"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"ZxkSHq-5Ryu-","colab_type":"code","colab":{}},"source":["monisha = False\n","loc = '/content/drive/My Drive/6.871 ML with HC/Project/' if monisha else '/content/drive/My Drive/Project/'\n","\n","import pandas as pd\n","from google.colab import drive\n","drive.mount('/content/drive')\n","import numpy as np\n","import pickle\n","import torch\n","import random\n","import ast\n","!pip install transformers\n","from transformers import *\n","\n","# https://huggingface.co/emilyalsentzer/Bio_ClinicalBERT\n","# Recitation Example: https://colab.research.google.com/drive/1dluu2EDp9NuE8FzMnw4M_6lQ66lcX-nh#scrollTo=h83JKPFeTZ4k\n","# Use Bio_Clinical BERT (trained on MIMIC III) through the transformers library\n","tokenizer = AutoTokenizer.from_pretrained(\"emilyalsentzer/Bio_ClinicalBERT\")\n","model = AutoModel.from_pretrained(\"emilyalsentzer/Bio_ClinicalBERT\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"CWjXrahPR5sG","colab_type":"code","colab":{}},"source":["def obtain_BERT_embeddings_new(txt, abbrev):\n","  #given a text with a unique abbrev, returns the BERT embeding of abbrev. \n","  tokenized_text = tokenizer.encode(txt, add_special_tokens=True)\n","  tokenized_abbrev = tokenizer.encode(abbrev, add_special_tokens=True)\n","  #below finds the index corresponding to our abbreviation\n","  try:\n","    index = [x for x in range(len(tokenized_text)) if tokenized_text[x:x+len(tokenized_abbrev)-2] == tokenized_abbrev[1:-1]][0] \n","    input_id = torch.tensor([tokenizer.encode(txt, add_special_tokens=True)])\n","    ##need to account for possibility if len(input_id)>512. BERT only takes in max token length 512. \n","    mode = 0\n","    if input_id.shape[1]>512:\n","      temp = input_id[0][0:512-len(tokenized_abbrev)+2].unsqueeze(0)\n","      temp2 = input_id[0][index:index+len(tokenized_abbrev)-2].unsqueeze(0)\n","      input_id = torch.cat([temp, temp2], dim=1) # we take the first 500 ish tokens for the sentence, and just append the abbreviation at the end. We will recover the embedding of the end abbreviation. \n","      mode = 1\n","    try:\n","      if mode == 1:\n","        embedding = model(input_id)[0][0][512-len(tokenized_abbrev)+2:512].detach().numpy()      \n","      else:\n","        embedding = model(input_id)[0][0][index:index+len(tokenized_abbrev)-2].detach().numpy() #we recover the BERT embedding for the abbreviation.\n","      return np.mean(embedding, axis=0)\n","    except IndexError:\n","      print(txt)\n","      print(tokenized_text)\n","      print(tokenized_abbrev)\n","      print(index)\n","  except IndexError:\n","      print(txt)\n","      print(tokenized_text)\n","      print(tokenized_abbrev)\n","      # print(index)\n","  return None"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"dvm4JKdBam6M","colab_type":"code","colab":{}},"source":["train = pd.read_csv(loc+\"data/train_mimic.csv\")\n","neg_train = pd.read_csv(loc+\"data/neg_train_mimic.csv\")\n","temp_df = pd.read_csv(loc+\"data/temp_test.csv\")\n","test = pd.read_csv(loc+\"data/test.csv\")\n","\n","##temp_df is basically test preprocessing. "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"-P_0pFqVK9qr","colab_type":"code","colab":{}},"source":["neg_train.head(5)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"LceMVJFpR6d2","colab_type":"code","colab":{}},"source":["## due to how we saved the .csv's many entries are strings when they are supposed to be arrays. This converts them back to arrays.\n","try:\n","  train[\"Abbreviation-embedding\"] = train[\"Abbreviation-embedding\"].apply(lambda x: ast.literal_eval(x))\n","  train[\"cui-embedding\"] = train[\"cui-embedding\"].apply(lambda x: ast.literal_eval(x))\n","  neg_train[\"Abbreviation-embedding\"] = neg_train[\"Abbreviation-embedding\"].apply(lambda x: ast.literal_eval(x))\n","  neg_train[\"incorrect-cui-embedding\"] = neg_train[\"incorrect-cui-embedding\"].apply(lambda x: ast.literal_eval(x))\n","  temp_df[\"Abbreviation-embedding\"] = temp_df[\"Abbreviation-embedding\"].apply(lambda x: ast.literal_eval(x))\n","  temp_df[\"CUI_embedding\"] = temp_df[\"CUI_embedding\"].apply(lambda x: ast.literal_eval(x))\n","  test[\"Abbreviation-embedding\"] = test[\"Abbreviation-embedding\"].apply(lambda x: ast.literal_eval(x))\n","  test[\"CUI_embedding\"] = test[\"CUI_embedding\"].apply(lambda x: ast.literal_eval(x))\n","  test[\"feature_vector\"] = test[\"feature_vector\"].apply(lambda x: ast.literal_eval(x))\n","except ValueError:\n","  print(\"All good!\")\n","\n","\n","train_final = train.drop([\"Abbreviation\", \"Long-form\", \"Text\", \"used_jaccard\", \"cui\"], axis=1)\n","train_final[\"feature_vector\"] = train_final[\"Abbreviation-embedding\"] + train_final[\"cui-embedding\"]\n","neg_train[\"feature_vector\"] = neg_train[\"Abbreviation-embedding\"]+neg_train[\"incorrect-cui-embedding\"]\n","combined_train_final = pd.concat([train_final[[\"label\", \"feature_vector\"]], neg_train[[\"label\",\"feature_vector\"]]])\n","\n","mask = np.random.rand(len(combined_train_final)) < 0.85\n","ttrain = combined_train_final[mask]\n","tvalid = combined_train_final[~mask]\n","print('Train dataset size: ', len(ttrain))\n","print('Test dataset size: ', len(tvalid))\n","\n","labels = ttrain.label.tolist()\n","features = ttrain[\"feature_vector\"].tolist()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"XUx3a7-Nr0YR","colab_type":"code","colab":{}},"source":["temp_df.to_csv(loc+'data/temp_test.csv')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"K_0dlkwhWZBr","colab_type":"code","colab":{}},"source":["from sklearn.neural_network import MLPClassifier\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.linear_model import LogisticRegressionCV"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"N_krD_lElVVA","colab_type":"code","colab":{}},"source":["from sklearn.metrics import f1_score, recall_score, accuracy_score, precision_score\n","\n","def evaluate_clf(clf, training, test):\n","  ##return accuracy\n","  # print(training[0][0:10], training[0][0:10])\n","  clf.fit(training[0], training[1])\n","  pred = clf.predict(test[0])\n","  f1 = f1_score(test[1], pred)\n","  recall = recall_score(test[1], pred)\n","  accuracy = accuracy_score(test[1], pred)\n","  precision = precision_score(test[1], pred)\n","  # accuracy = sum([pred[i]==test[1][i] for i in range(len(pred))])/len(pred)\n","  return accuracy, recall, precision, f1, clf\n","\n","def generate_fake_data(temp_df, fakesize):  \n","  fake_data = temp_df.sample(fakesize)[[\"Abbreviation-embedding\", \"Long_Form\"]]\n","  # fake_data[\"Abbreviation-embedding\"] = fake_data[\"Abbreviation-embedding\"].apply(lambda x: ast.literal_eval(x))\n","  fake_data[\"CUI_embedding\"] = fake_data[\"Abbreviation-embedding\"].apply(lambda x: random.choice(temp_df[\"CUI_embedding\"].tolist()))\n","  # fake_data[\"CUI_embedding\"] = fake_data[\"CUI_embedding\"].apply(lambda x: ast.literal_eval(x))\n","  fake_data[\"label\"] = fake_data[\"Abbreviation-embedding\"].apply(lambda x: 0)\n","  fake_data[\"feature_vector\"] = fake_data[\"Abbreviation-embedding\"]+ fake_data[\"CUI_embedding\"]\n","  return fake_data\n","\n","def compare_without_with_data(clf, CASIsize, weight, features, labels, ttrain, fake=False):\n","  fakesize = CASIsize*weight\n","  msk = np.random.rand(len(test)) < 0.75\n","  new_test_7500 = test[msk]\n","  left_over = test[~msk]\n","  add_data = left_over.sample(CASIsize)[[\"feature_vector\", \"label\"]]\n","  if fake==True:\n","    fake_test = generate_fake_data(temp_df, 7500)\n","  fake_data = generate_fake_data(temp_df, fakesize)\n","  new_test_7500 = pd.concat([new_test_7500, fake_test])\n","  new_ttrain = pd.concat([ttrain]+[add_data]*weight + [fake_data])\n","  new_features = new_ttrain[\"feature_vector\"].tolist()\n","  new_labels = new_ttrain[\"label\"].tolist()\n","  \n","  new_accuracy, recall, precision, f1, clf = evaluate_clf(clf, [new_features, new_labels], [new_test_7500[\"feature_vector\"].tolist(), new_test_7500[\"label\"].tolist()])\n","  # old_accuracy = evaluate_clf(clf, [features, labels], [test[\"feature_vector\"].tolist(), test[\"label\"].tolist()])\n","  print(\"accuracy is \", new_accuracy)\n","  print(\"f1 score is \", f1)\n","  print(\"recall score is \", recall)\n","  print(\"precision score is\", precision)\n","  # print(\"old accuracy is \", old_accuracy)\n","  return new_accuracy, clf"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"wzcf03Y1umA7","colab_type":"code","colab":{}},"source":["# uncomment this if you want to train various models. \n","\n","from warnings import filterwarnings\n","filterwarnings('ignore')\n","\n","arr = [RandomForestClassifier(), LogisticRegressionCV(), MLPClassifier((100,100,100,100))]\n","randomweights = [(100,4), (200,4), (1000,4), (2000,4)]\n","# randomweights=[(0,1)]\n","accs = []\n","for w in randomweights:\n","  w_acc = []\n","  for c in arr:\n","    print(w)\n","    print(c.__class__.__name__)\n","    acc, c = compare_without_with_data(c, w[0], w[1], features, labels, ttrain, fake=True)\n","    w_acc.append(acc)\n","  accs.append(w_acc)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"sqW1jJHvWi00","colab_type":"code","colab":{}},"source":["with open(loc+\"/data/perfresults1.txt\", 'r', encoding = \"ISO-8859-1\") as f:\n","      lines1 = f.readlines()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"mmWRKJHUXO-Z","colab_type":"code","colab":{}},"source":["df1 = pd.DataFrame(columns=['Dataset', 'Classifier', 'Accuracy'])\n","for i in range(0, len(lines1), 3):\n","  t = [lines1[i][:-1], lines1[i+1][:-1], lines1[i+2][:-1]]\n","  acc = float(t[2].split(' ')[-1].strip())\n","  # print([t[0], t[1], acc])\n","  df1 = df1.append({'Dataset': t[0], 'Classifier': t[1], 'Accuracy': acc}, ignore_index=True)\n","df1.head()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"04uViJVSZ_AT","colab_type":"code","colab":{}},"source":["import seaborn as sns\n","sns.set()\n","sns.barplot(x=\"Dataset\", y=\"Accuracy\",\n","                     hue=\"Classifier\",\n","                    #  marker = 'o',\n","                    #  s = 100,\n","                     data=df1)\n","plt.gcf().set_size_inches(10, 8)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"z9oToZyBi8Kt","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"OwiiWYaVanS8","colab_type":"code","colab":{}},"source":["with open(loc+\"/data/perfresults2.txt\", 'r', encoding = \"ISO-8859-1\") as f:\n","  lines2 = f.readlines()\n","with open(loc+\"/data/perfresults3.txt\", 'r', encoding = \"ISO-8859-1\") as f:\n","  lines3 = f.readlines()\n","lines2 = lines2+lines3\n","# print(lines2)\n","df = pd.DataFrame(columns=['Dataset', 'Classifier', 'Accuracy', 'F1', 'Recall', 'Precision'])\n","for i in range(0, len(lines2), 6):\n","  t = [lines2[i][:-1], lines2[i+1][:-1], lines2[i+2][:-1], lines2[i+3][:-1], lines2[i+4][:-1], lines2[i+5][:-1]]\n","  acc, f1, recall, precision = float(t[2].split(' ')[-1].strip()), float(t[3].split(' ')[-1].strip()), float(t[4].split(' ')[-1].strip()), float(t[5].split(' ')[-1].strip())\n","  # print([t[0], t[1], acc, f1, recall, precision])\n","  df = df.append({'Dataset': t[0], 'Classifier': t[1], 'Accuracy': acc, 'F1': f1, 'Recall': recall, 'Precision': precision}, ignore_index=True)\n","df"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"NhUCxKSrcb4W","colab_type":"code","colab":{}},"source":["import seaborn as sns\n","sns.set()\n","sns.barplot(x=\"Dataset\", y=\"F1\",\n","                     hue=\"Classifier\",\n","                    #  marker = 'o',\n","                    #  s = 100,\n","                     data=df).set_title('F1-Score')\n","plt.gcf().set_size_inches(10, 8)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"0PDE_Jw5HfAJ","colab_type":"code","colab":{}},"source":["# CASIsize = 1000\n","# weight = 0\n","# fakesize = CASIsize*weight\n","# msk = np.random.rand(len(test)) < 0.75\n","# new_test_7500 = test[msk]\n","# left_over = test[~msk]\n","# add_data = left_over.sample(CASIsize)[[\"feature_vector\", \"label\"]]\n","# fake_data = generate_fake_data(temp_df, fakesize)\n","# new_ttrain = pd.concat([ttrain])\n","# new_features = new_ttrain[\"feature_vector\"].tolist()\n","# new_labels = new_ttrain[\"label\"].tolist()\n","\n","# rf_clf2 = RandomForestClassifier(random_state=0)\n","# rf_clf2.fit(new_features, new_labels)\n","# rf_pred2 = rf_clf2.predict(new_test_7500[\"feature_vector\"].tolist())\n","# print(\"Accuracy = \", sum([rf_pred2[i]==new_test_7500[\"label\"].tolist()[i] for i in range(len(rf_pred2))])/len(rf_pred2))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DcYp8JbsV_7c","colab_type":"text"},"source":["## Checking that our model uses character-level information. \n","Hypotheses: Bad accuracy on randomized abbreviations. \n","Generate acronym-based abbreviations. Use this to discover 'new' abbreviations."]},{"cell_type":"code","metadata":{"id":"cWjtRLCJfd75","colab_type":"code","colab":{}},"source":["##let's fix a prediction model.\n","c = MLPClassifier((100,100,100,100))\n","_, clf = compare_without_with_data(c, 2000, 1, features, labels, ttrain)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"o02N9YLMhRA-","colab_type":"code","colab":{}},"source":["def generate_abbreviation(words):\n","  arr = words.split(' ')\n","  if len(words.split(' '))>=2:\n","    return ''.join([i[0] for i in arr]).upper()\n","  else:\n","    return (words[0:2]).upper()\n","\n","import string\n","df = temp_df.sample(1000)[[\"Long_Form\", \"Abbr\", \"Abbr_In_Note\", \"Note_Text\", \"CUI_embedding\", \"Abbreviation-embedding\" ]]\n","df.head(5)\n","df[\"random-abbrev\"] = df[\"Abbr\"].apply(lambda x: ''.join(random.choices(string.ascii_uppercase, k=len(x))))\n","df[\"random-annotated-text\"] = df.apply(lambda x: x['Note_Text'].replace(x[\"Abbr_In_Note\"], x[\"random-abbrev\"]), axis=1 )\n","df[\"acronym-abbrev\"] =df[\"Long_Form\"].apply(lambda x: generate_abbreviation(x)) \n","df[\"acronym-annotated-text\"] = df.apply(lambda x: x['Note_Text'].replace(x[\"Abbr_In_Note\"], x[\"acronym-abbrev\"]), axis=1 )\n","\n","df[\"random-abbrev-embed\"] = df.apply(lambda x: obtain_BERT_embeddings_new(x[\"random-annotated-text\"], x[\"random-abbrev\"]), axis=1)\n","df[\"acronym-abbrev-embed\"] = df.apply(lambda x: obtain_BERT_embeddings_new(x[\"acronym-annotated-text\"], x[\"acronym-abbrev\"]), axis=1)\n","\n","df[\"random_feature_vectors\"] = df.apply(lambda x: np.concatenate([x[\"random-abbrev-embed\"], x[\"CUI_embedding\"]]), axis = 1)\n","df[\"feature_vectors\"] = df.apply(lambda x: np.concatenate([x[\"Abbreviation-embedding\"], x[\"CUI_embedding\"]]), axis = 1)\n","df[\"acronym_feature_vectors\"] = df.apply(lambda x: np.concatenate([x[\"acronym-abbrev-embed\"], x[\"CUI_embedding\"]]), axis = 1)\n","df[\"model_pred\"] = df[\"feature_vectors\"].apply(lambda x: clf.predict([x]))\n","df[\"random_pred\"] = df[\"random_feature_vectors\"].apply(lambda x: clf.predict([x]))\n","df[\"acronym_pred\"] = df[\"acronym_feature_vectors\"].apply(lambda x: clf.predict([x]))\n","\n","results = df[[\"Long_Form\", \"Abbr\", \"Abbr_In_Note\", \"Note_Text\", \"random-abbrev\", \"acronym-abbrev\", \"model_pred\", \"random_pred\", \"acronym_pred\"]]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"AlsElZbgyejb","colab_type":"code","colab":{}},"source":["len(results[results[\"random_pred\"] == 1])/len(results)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"V_ABzQ-M_FQP","colab_type":"code","colab":{}},"source":["len(results[results[\"acronym_pred\"]==1])/len(results)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"rqIt81kG5EBN","colab_type":"code","colab":{}},"source":["generated_abbreviations = results[(results[\"acronym-abbrev\"]!=results[\"Abbr\"]) & (results[\"acronym_pred\"]==1)]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"T1qQvt91vw8y","colab_type":"code","colab":{}},"source":["generated_abbreviations"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"cXo9crEriY_3","colab_type":"code","colab":{}},"source":["results[results[\"acronym-abbrev\"].isin(set(generated_abbreviations[\"acronym-abbrev\"]))]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"NHU5V25pTXeI","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"CQG8t1s8e-6u","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"idwx4c7zIQxG","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"faGZ1QUzfYVA","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}